{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "649c84f2-362c-4812-8b56-a6986389b056",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "\n",
        "import os\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from typing import List\n",
        "from dotenv import load_dotenv\n",
        "import litellm #for gemini\n",
        "from openai import OpenAI #for OpenAI\n",
        "import anthropic #for Claude \n",
        "import gradio as gr "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aaed6594-ce83-4f62-9b19-87c040d74cc8",
      "metadata": {},
      "source": [
        "# set-up Frontier Model {Use one out of two method shown below}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1df99dbb-0423-4587-a40d-67e9dc15225d",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# --- Method 1: Paste your keys directly ---If a user does this and commits the file to GitHub, their secret key will be exposed to the public.\n",
        "# Replace the placeholder text with your actual API keys.\n",
        "\n",
        "# For OpenAI, your key usually starts with \"sk-proj...\"\n",
        "os.environ['OPENAI_API_KEY'] = \"PASTE_YOUR_OPENAI_API_KEY_HERE\" \n",
        "\n",
        "# For Anthropic, your key usually starts with \"sk-ant-api03...\"\n",
        "os.environ['ANTHROPIC_API_KEY'] = \"PASTE_YOUR_ANTHROPIC_API_KEY_HERE\"\n",
        "\n",
        "# For Google Gemini\n",
        "os.environ['GEMINI_API_KEY'] = \"PASTE_YOUR_GEMINI_API_KEY_HERE\"\n",
        "\n",
        "\n",
        "# --- Method 2: Load keys from a .env file ( if you have api in .env) ---\n",
        "# If you have your API keys in a .env file, you can use this method instead.\n",
        "# First, uncomment the line below to install the required library:\n",
        "# !pip install python-dotenv\n",
        "\n",
        "# Then, uncomment the following lines of code:\n",
        "# from dotenv import load_dotenv\n",
        "# print(\"Loading keys from .env file...\")\n",
        "# load_dotenv()\n",
        "# print(\"✅ Keys loaded.\")\n",
        "\n",
        "\n",
        "# --- Verification Step ---\n",
        "# This part of the code checks if the keys have been loaded correctly.\n",
        "print(\"Verifying API Keys...\")\n",
        "\n",
        "if os.getenv(\"OPENAI_API_KEY\") and os.getenv(\"OPENAI_API_KEY\") != \"PASTE_YOUR_OPENAI_API_KEY_HERE\":\n",
        "    print(\"✅ OpenAI API Key is set.\")\n",
        "else:\n",
        "    print(\"❌ OpenAI API Key is NOT set.\")\n",
        "\n",
        "if os.getenv(\"ANTHROPIC_API_KEY\") and os.getenv(\"ANTHROPIC_API_KEY\") != \"PASTE_YOUR_ANTHROPIC_API_KEY_HERE\":\n",
        "    print(\"✅ Anthropic API Key is set.\")\n",
        "else:\n",
        "    print(\"❌ Anthropic API Key is NOT set.\")\n",
        "    \n",
        "if os.getenv(\"GEMINI_API_KEY\") and os.getenv(\"GEMINI_API_KEY\") != \"PASTE_YOUR_GEMINI_API_KEY_HERE\":\n",
        "    print(\"✅ Gemini API Key is set.\")\n",
        "else:\n",
        "    print(\"❌ Gemini API Key is NOT set.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fe33781-89a4-420d-a074-18fdcf48dbc9",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Connect to OpenAI, Anthropic and Google; comment out the Claude or Google lines if you're not using them\n",
        "\n",
        "openai = OpenAI()\n",
        "\n",
        "claude = anthropic.Anthropic()\n",
        "\n",
        "litellm.completion()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07ac5d5a-ea23-4127-99dd-b8dded8dca35",
      "metadata": {},
      "source": [
        "# Start the Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfb26027-cd6b-4165-8668-249443e9df2b",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# This cell defines a class to fetch and parse the text content from a webpage.\n",
        "\n",
        "class Website:\n",
        "    url: str\n",
        "    title: str\n",
        "    text: str\n",
        "\n",
        "    def __init__(self, url):\n",
        "        self.url = url\n",
        "        response = requests.get(url)\n",
        "        self.body = response.content\n",
        "        soup = BeautifulSoup(self.body, 'html.parser')\n",
        "        self.title = soup.title.string if soup.title else \"No title found\"\n",
        "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
        "            irrelevant.decompose()\n",
        "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
        "\n",
        "    def get_contents(self):\n",
        "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9036735c-bdb8-4e4c-aeea-517c23b911bd",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "system_message = \"You are an assistant that analyzes the contents of a company website landing page \\\n",
        "and creates a short brochure about the company for prospective customers, investors and recruits. Respond in markdown.\"\n",
        "\n",
        "\n",
        "# Function to stream from OpenAI models\n",
        "def stream_gpt(prompt: str):\n",
        "    openai_client = OpenAI()\n",
        "    stream = openai_client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_message},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        stream=True,\n",
        "    )\n",
        "    \n",
        "    response = \"\"\n",
        "    for chunk in stream:\n",
        "        content = chunk.choices[0].delta.content or \"\"\n",
        "        response += content\n",
        "        yield response\n",
        "\n",
        "# Function to stream from Anthropic models\n",
        "def stream_claude(prompt: str):\n",
        "    claude_client = anthropic.Anthropic()\n",
        "    stream = claude_client.messages.stream(\n",
        "        model=\"claude-3-haiku-20240307\",\n",
        "        max_tokens=2048,\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        system=system_message\n",
        "    )\n",
        "    \n",
        "    response = \"\"\n",
        "    with stream as s:\n",
        "        for text in s.text_stream:\n",
        "            response += text\n",
        "            yield response\n",
        "\n",
        "# Function to stream from Gemini models using LiteLLM\n",
        "def stream_gemini(prompt: str):\n",
        "    stream = litellm.completion(\n",
        "        model=\"gemini/gemini-1.5-flash\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_message},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        stream=True\n",
        "    )\n",
        "\n",
        "    response = \"\"\n",
        "    for chunk in stream:\n",
        "        content = chunk.choices[0].delta.content or \"\"\n",
        "        response += content\n",
        "        yield response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b1cb44c3-ac2d-4482-96cf-49d21f0b176a",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def stream_brochure(company_name, url, model):\n",
        "    yield \"\"\n",
        "    prompt = f\"Please generate a company brochure for {company_name}. Here is their landing page:\\n\"\n",
        "    prompt += Website(url).get_contents()\n",
        "    if model==\"GPT\":\n",
        "        result = stream_gpt(prompt)\n",
        "    elif model==\"Claude\":\n",
        "        result = stream_claude(prompt)\n",
        "    else:\n",
        "        raise ValueError(\"Unknown model\")\n",
        "    yield from result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dd86f866-6032-49d1-b986-6cfe99fab235",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# This cell uses Gradio to create and launch the web interface for the application.\n",
        "view = gr.Interface(\n",
        "    fn=stream_brochure,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Company name:\"),\n",
        "        gr.Textbox(label=\"Landing page URL including http:// or https://\"),\n",
        "        gr.Dropdown([\"GPT\", \"Claude\"], label=\"Select model\")],\n",
        "    outputs=[gr.Markdown(label=\"Brochure:\")],\n",
        "    flagging_mode=\"never\"\n",
        ")\n",
        "view.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b28227d4-c189-41e3-8f6c-de83aae9b955",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.13 (XPython)",
      "language": "python",
      "name": "xpython"
    },
    "language_info": {
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
